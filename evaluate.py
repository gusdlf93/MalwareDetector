import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from torch.autograd import Variable
from torch.utils.data import DataLoader
from sklearn.model_selection import train_test_split
# from Android.data_loader_0709 import Android_loader, AM_CR_CL_loader
# from model import Android_MCNN, Android_MCNN2, Android_MCNN3, Android_MCNN4, load_MCNN4, BasicBlock, Embedded_MFCN, Embedded_MFCN2
from model_0517 import Android_MCNN, Android_MCNN2, Android_MCNN3, Android_MCNN4, load_MCNN4, BasicBlock, Embedded_MFCN

from Android.data_loader_0709 import Android_loader, AM_CR_CL_loader
from torch.utils.tensorboard import SummaryWriter
from torchvision import transforms
import time
from torch.utils.data import Dataset, Subset, random_split, SubsetRandomSampler, BatchSampler
from torchvision import models
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
from sklearn import svm, metrics
device = torch.device('cuda')

pad_size = 2000
#pad_size = 40000
n_section = 6
data_option = 1

transform = transforms.Compose([transforms.ToTensor()])

train_path = r'F:\server_tmp\pycharm_project_803\Data\CR_AM_20(train)'
val_path = r'F:\server_tmp\pycharm_project_803\Data\CR_AM_20(val)'
test_path = r'F:\server_tmp\pycharm_project_803\Data\CR_AM_20(test)'

train_dataset = AM_CR_CL_loader(train_path, transform=transform, pad_size = pad_size, n_section=n_section, data_option=data_option)
val_dataset = AM_CR_CL_loader(val_path, transform=transform, pad_size = pad_size, n_section=n_section, data_option=data_option)
test_dataset = AM_CR_CL_loader(test_path, transform=transform, pad_size = pad_size, n_section=n_section, data_option=data_option)

train_index = np.arange(len(train_dataset))
val_index =np.arange(len(val_dataset))
test_index = np.arange(len(test_dataset))

def collect(batch):
    data = []
    label = []
    for i in batch:
        for j in range(len(i[0])):
            i[0][j] = i[0][j].unsqueeze(dim=0)
        data.append(i[0])
        label.append(i[1])
    label = torch.Tensor(label)
    return data,label

batch_size = 2

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, sampler=SubsetRandomSampler(train_index), collate_fn=(collect), drop_last=True)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, sampler=SubsetRandomSampler(val_index), collate_fn=(collect), drop_last=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, sampler=SubsetRandomSampler(test_index), collate_fn=(collect), drop_last=True)

model_path = r'F:\server_tmp\pycharm_project_510\Model\Basic_6_section\2021_7_19_ANdroid_6_tream_0.9195278969957081_0.9324034334763949.pth'
#model_path = r'F:\server_tmp\pycharm_project_510\Model\Embedded2\2021_5_20_Embedded_Model2_6_sections_kernel_5_4659(A=94.3).pth'

option = 1
import time

# if option == 1:#CNN
pred_time = time.time()
model = torch.load(model_path)
model.eval()
model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters())

acc = 0
total = 0
test_loss = 0
Y_Pred = []
Y_Test = []

with torch.no_grad():
    for i, data in enumerate(test_loader, 1):  ##training batch
        print(i)
        inputs, labels = data
        labels = labels.to(device)
        for j in range(len(inputs)):
            for k in range(len(inputs[j])):
                inputs[j][k] = inputs[j][k].to(device)
        Y_Test.append(labels.detach().cpu().numpy())
        # 순전파 + 역전파 + 최적화를 한 후
        outputs = model(inputs)
        Y_Pred.append(outputs.detach().cpu().numpy())

        if batch_size != 1:
            acc += np.sum(
                (torch.argmax(outputs, axis=1).long().detach().cpu() == labels.long().detach().cpu()).numpy())
        else:
            acc += np.sum((torch.argmax(outputs[0].reshape(1, 20).cuda().detach().cpu(),
                                        axis=1).long() == labels.long().cuda().detach().cpu()).numpy())

        total += batch_size

print(f"acc = {acc / total}")
Y_Test_class = np.asarray(Y_Test).reshape(len(Y_Test) * len(Y_Test[0]))
Y_Pred_class = np.argmax(Y_Pred, axis=2).reshape(len(Y_Pred) * len(Y_Pred[0]))

pred_time = time.time() - pred_time
print("pred_time = {}", pred_time)
print(classification_report(Y_Test_class, Y_Pred_class, digits=3))
print(confusion_matrix(Y_Test_class, Y_Pred_class))
    # np.array([np.array((r, f1))[:, i] for i in range(len(r))])

    #import pandas as pd
    # import numpy as np
    # df  =pd.DataFrame(cm)
    # df.to_csv('/tmp/pycharm_project_510/sample.csv', index=False)