import torch.nn as nn
import torch
import torchvision.models as models
import math
from bottleneck_transformer_pytorch import BottleStack
import numpy as np

class Android_MCNN4(nn.Module):  # 일자로 붙인 버전에서 GAP해결
    def __init__(self, channel, kernel_size=3, stride=1, padding=1, n_class=20, n_section=12, batch_size=None):
        super().__init__()

        self.relu = nn.ReLU()
        self.sm = nn.Softmax()
        self.n_section = n_section
        self.batch_size = batch_size
        self.maxpool1d = torch.nn.MaxPool1d(kernel_size=2)
        self.drop = nn.Dropout(0.5)
        self.aap = nn.AdaptiveAvgPool1d((1), )
        self.amp = nn.AdaptiveAvgPool1d((4), )  # adaptive max pooling
        self.sigmoid = nn.Sigmoid()

        self.conv1d = nn.ModuleList()
        for i in range(n_section):
            self.conv1d.append(nn.Conv1d(1, channel, kernel_size=kernel_size, stride=stride, padding=padding))

        self.conv2d = nn.ModuleList()
        for i in range(n_section):
            self.conv2d.append(nn.Conv1d(channel, channel * 2, kernel_size=kernel_size, stride=stride, padding=padding))

        self.conv3d = nn.ModuleList()
        for i in range(n_section):
            self.conv3d.append(
                nn.Conv1d(channel * 2, channel * 4, kernel_size=kernel_size, stride=stride, padding=padding))

        self.conv4d = nn.ModuleList()
        for i in range(n_section):
            self.conv4d.append(
                nn.Conv1d(channel * 4, channel * 8, kernel_size=kernel_size, stride=stride, padding=padding))

        self.fc = nn.Linear(channel * 8 * n_section * 4,
                            channel * 8)  # (channel * section * adaptive maxpooling output)
        # self.fc = nn.Linear(channel * 8 * n_section, channel * 8)  # (channel * section * adaptive maxpooling output)
        self.fc2 = nn.Linear(channel * 8, n_class)

    def forward(self, x):
        pred = []
        for b in range(self.batch_size):
            for i in range(self.n_section):
                try:
                    x[b][i] = self.conv1d[i](x[b][i])
                    x[b][i] = self.relu(x[b][i])
                    x[b][i] = self.maxpool1d(x[b][i])

            for i in range(self.n_section):
                x[b][i] = self.conv2d[i](x[b][i])
                x[b][i] = self.relu(x[b][i])
                x[b][i] = self.maxpool1d(x[b][i])

            for i in range(self.n_section):
                x[b][i] = self.conv3d[i](x[b][i])
                x[b][i] = self.relu(x[b][i])
                x[b][i] = self.maxpool1d(x[b][i])

            for i in range(self.n_section):
                x[b][i] = self.conv4d[i](x[b][i])
                x[b][i] = self.relu(x[b][i])
                x[b][i] = self.maxpool1d(x[b][i])
                # adaptive max pooling
                x[b][i] = self.amp(x[b][i])
                # x[b][i] = self.aap(x[b][i])

            c_x = torch.cat([x[b][i] for i in range(self.n_section)], dim=1)
            c_x = torch.flatten(c_x)
            c_x = self.drop(c_x)
            c_x = self.fc(c_x)
            c_x = self.drop(c_x)
            c_x = self.fc2(c_x)
            pred.append(c_x)

        if self.batch_size != 1:
            pred = torch.cat([i.reshape(1, 20) for i in pred], dim=0)
        return pred

class BasicBlock(nn.Module):
    def __init__(self, inplanes, outplanes, stride=1, base_width=64, norm_layer=None, batch_size=None, n_section=None,
                 groups=1, dilation=1, downsampling=None, ):
        super(BasicBlock, self).__init__()
        if norm_layer is None:
            norm_layer = nn.LayerNorm
        if groups != 1 or base_width != 64:
            raise ValueError('BasicBlock only supports groups=1 and base_width=64')
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1

        self.conv1 = conv1d(inplanes, outplanes, stride=stride)
        self.ln1 = norm_layer(outplanes)
        self.relu = nn.ReLU()
        self.stride = stride
        self.batch_size = batch_size
        self.n_section = n_section
        self.maxpool1d = torch.nn.MaxPool1d(kernel_size=2)

    def forward(self, x):
        identity = x

        if self.batch_size != 1:
            for b in range(self.batch_size):
                for i in range(self.n_section):
                    x[b][i] = self.conv1(x[b][i])
                    x[b][i] = self.ln1(x[b][i].unsqueeze(-1))
                    x[b][i] = x[b][i].squeeze(-1)
                    x[b][i] = self.maxpool1d(x[b][i])

                for i in range(self.n_section):
                    x[b][i] = torch.add(x[b][i], identity[b][i])
                    x[b][i] = self.relu(x[b][i])
            return x
        else:
            for i in range(self.n_section):
                x[0][i] = self.conv1(x[0][i])
                x[0][i] = self.ln1(x[0][i].unsqueeze(-1))
                x[0][i] = x[0][i].squeeze(-1)
                x[0][i] = self.maxpool1d(x[0][i])

            for i in range(self.n_section):
                x[0][i] = torch.add(x[0][i], identity[0][i])
                x[0][i] = self.relu(x[0][i])

            return x


def conv1d(inplain, outplain, stride=1, groups=1, dilation=1):
    return nn.Conv1d(inplain, outplain, kernel_size=3, stride=stride, padding=dilation, groups=groups, bias=False,
                     dilation=dilation)