import torch.nn as nn
import torch
import torchvision.models as models
import math
from bottleneck_transformer_pytorch import BottleStack
import numpy as np

# models.resnet18()

class Android_MCNN2(nn.Module):  # 일자로 붙인 버전?
    def __init__(self, channel, kernel_size=3, stride=1, padding=1, n_class=20, n_section=12, batch_size=None):
        super().__init__()

        self.relu = nn.ReLU()
        self.sm = nn.Softmax()
        self.n_section = 12
        self.batch_size = batch_size
        self.maxpool1d = torch.nn.MaxPool1d(kernel_size=2)
        self.drop = nn.Dropout(0.5)
        self.aap = nn.AdaptiveAvgPool1d((1), )

        self.conv1d = nn.ModuleList()
        for i in range(n_class):
            self.conv1d.append(nn.Conv1d(1, channel, kernel_size=kernel_size, stride=stride, padding=padding))

        self.conv2d = nn.ModuleList()
        for i in range(n_class):
            self.conv2d.append(nn.Conv1d(channel, channel * 2, kernel_size=kernel_size, stride=stride, padding=padding))

        self.conv3d = nn.ModuleList()
        for i in range(n_class):
            self.conv3d.append(
                nn.Conv1d(channel * 2, channel * 4, kernel_size=kernel_size, stride=stride, padding=padding))

        self.conv4d = nn.ModuleList()
        for i in range(n_class):
            self.conv4d.append(
                nn.Conv1d(channel * 4, channel * 6, kernel_size=kernel_size, stride=stride, padding=padding))

        self.conv5d = nn.ModuleList()
        for i in range(n_class):
            self.conv5d.append(
                nn.Conv1d(channel * 6, channel * 8, kernel_size=kernel_size, stride=stride, padding=padding))

        self.fc = nn.Linear(channel * 8, channel * 8)
        self.fc2 = nn.Linear(channel * 8, n_class)

    def forward(self, x):
        pred = []
        for b in range(self.batch_size):
            for i in range(self.n_section):
                x[b][i] = self.conv1d[i](x[b][i])
                x[b][i] = self.relu(x[b][i])
                x[b][i] = self.maxpool1d(x[b][i])

            for i in range(self.n_section):
                x[b][i] = self.conv2d[i](x[b][i])
                x[b][i] = self.relu(x[b][i])
                x[b][i] = self.maxpool1d(x[b][i])

            for i in range(self.n_section):
                x[b][i] = self.conv3d[i](x[b][i])
                x[b][i] = self.relu(x[b][i])
                x[b][i] = self.maxpool1d(x[b][i])

            for i in range(self.n_section):
                x[b][i] = self.conv4d[i](x[b][i])
                x[b][i] = self.relu(x[b][i])
                x[b][i] = self.maxpool1d(x[b][i])

            for i in range(self.n_section):
                x[b][i] = self.conv5d[i](x[b][i])
                x[b][i] = self.relu(x[b][i])
                x[b][i] = self.maxpool1d(x[b][i])

            c_x = torch.cat([x[b][i] for i in range(self.n_section)], dim=2)
            c_x = self.aap(c_x)
            c_x = torch.flatten(c_x)
            c_x = self.drop(c_x)
            c_x = self.fc(c_x)
            c_x = self.drop(c_x)
            c_x = self.fc2(c_x)
            pred.append(c_x)

        if self.batch_size != 1:
            pred = torch.cat([i.reshape(1, 20) for i in pred], dim=0)
        return pred


class Android_MCNN3(nn.Module):  # 일자로 붙인 버전?
    def __init__(self, channel, kernel_size=3, stride=1, padding=1, n_class=20, n_section=12, batch_size=None):
        super().__init__()

        self.relu = nn.ReLU()
        self.sm = nn.Softmax()
        self.n_section = 12
        self.batch_size = batch_size
        self.maxpool1d = torch.nn.MaxPool1d(kernel_size=2)
        self.drop = nn.Dropout(0.5)
        self.aap = nn.AdaptiveAvgPool1d((1), )

        self.conv1d = nn.ModuleList()
        for i in range(n_section):
            self.conv1d.append(nn.Conv1d(1, channel, kernel_size=kernel_size, stride=stride, padding=padding))

        self.conv2d = nn.ModuleList()
        for i in range(n_section):
            self.conv2d.append(nn.Conv1d(channel, channel * 2, kernel_size=kernel_size, stride=stride, padding=padding))

        self.conv3d = nn.ModuleList()
        for i in range(n_section):
            self.conv3d.append(
                nn.Conv1d(channel * 2, channel * 4, kernel_size=kernel_size, stride=stride, padding=padding))

        self.conv4d = nn.ModuleList()
        for i in range(n_section):
            self.conv4d.append(
                nn.Conv1d(channel * 4, channel * 8, kernel_size=kernel_size, stride=stride, padding=padding))

        self.fc = nn.Linear(channel * 8, channel * 8)
        self.fc2 = nn.Linear(channel * 8, n_class)

    def forward(self, x):
        pred = []
        for b in range(self.batch_size):
            for i in range(self.n_section):
                x[b][i] = self.conv1d[i](x[b][i])
                x[b][i] = self.relu(x[b][i])
                x[b][i] = self.maxpool1d(x[b][i])

            for i in range(self.n_section):
                x[b][i] = self.conv2d[i](x[b][i])
                x[b][i] = self.relu(x[b][i])
                x[b][i] = self.maxpool1d(x[b][i])

            for i in range(self.n_section):
                x[b][i] = self.conv3d[i](x[b][i])
                x[b][i] = self.relu(x[b][i])
                x[b][i] = self.maxpool1d(x[b][i])

            for i in range(self.n_section):
                x[b][i] = self.conv4d[i](x[b][i])
                x[b][i] = self.relu(x[b][i])
                x[b][i] = self.maxpool1d(x[b][i])

            c_x = torch.cat([x[b][i] for i in range(self.n_section)], dim=2)
            c_x = self.aap(c_x)
            c_x = torch.flatten(c_x)
            c_x = self.drop(c_x)
            c_x = self.fc(c_x)
            c_x = self.drop(c_x)
            c_x = self.fc2(c_x)
            pred.append(c_x)

        if self.batch_size != 1:
            pred = torch.cat([i.reshape(1, 20) for i in pred], dim=0)
        return pred


class Android_MCNN4(nn.Module):  # 일자로 붙인 버전에서 GAP해결
    def __init__(self, channel, kernel_size=3, stride=1, padding=1, n_class=20, n_section=12, batch_size=None):
        super().__init__()

        self.relu = nn.ReLU()
        self.sm = nn.Softmax()
        self.n_section = n_section
        self.batch_size = batch_size
        self.maxpool1d = torch.nn.MaxPool1d(kernel_size=2)
        self.drop = nn.Dropout(0.5)
        self.aap = nn.AdaptiveAvgPool1d((1), )
        self.amp = nn.AdaptiveAvgPool1d((4), )  # adaptive max pooling
        self.sigmoid = nn.Sigmoid()

        self.conv1d = nn.ModuleList()
        for i in range(n_section):
            self.conv1d.append(nn.Conv1d(1, channel, kernel_size=kernel_size, stride=stride, padding=padding))

        self.conv2d = nn.ModuleList()
        for i in range(n_section):
            self.conv2d.append(nn.Conv1d(channel, channel * 2, kernel_size=kernel_size, stride=stride, padding=padding))

        self.conv3d = nn.ModuleList()
        for i in range(n_section):
            self.conv3d.append(
                nn.Conv1d(channel * 2, channel * 4, kernel_size=kernel_size, stride=stride, padding=padding))

        self.conv4d = nn.ModuleList()
        for i in range(n_section):
            self.conv4d.append(
                nn.Conv1d(channel * 4, channel * 8, kernel_size=kernel_size, stride=stride, padding=padding))

        self.fc = nn.Linear(channel * 8 * n_section * 4,
                            channel * 8)  # (channel * section * adaptive maxpooling output)
        # self.fc = nn.Linear(channel * 8 * n_section, channel * 8)  # (channel * section * adaptive maxpooling output)
        self.fc2 = nn.Linear(channel * 8, n_class)

    def forward(self, x):
        pred = []
        for b in range(self.batch_size):
            for i in range(self.n_section):
                try:
                    x[b][i] = self.conv1d[i](x[b][i])
                    x[b][i] = self.relu(x[b][i])
                    x[b][i] = self.maxpool1d(x[b][i])
                except IndexError:
                    print("Dbg")

            for i in range(self.n_section):
                x[b][i] = self.conv2d[i](x[b][i])
                x[b][i] = self.relu(x[b][i])
                x[b][i] = self.maxpool1d(x[b][i])

            for i in range(self.n_section):
                x[b][i] = self.conv3d[i](x[b][i])
                x[b][i] = self.relu(x[b][i])
                x[b][i] = self.maxpool1d(x[b][i])

            for i in range(self.n_section):
                x[b][i] = self.conv4d[i](x[b][i])
                x[b][i] = self.relu(x[b][i])
                x[b][i] = self.maxpool1d(x[b][i])
                # adaptive max pooling
                x[b][i] = self.amp(x[b][i])
                # x[b][i] = self.aap(x[b][i])

            c_x = torch.cat([x[b][i] for i in range(self.n_section)], dim=1)
            c_x = torch.flatten(c_x)
            c_x = self.drop(c_x)
            c_x = self.fc(c_x)
            c_x = self.drop(c_x)
            c_x = self.fc2(c_x)
            pred.append(c_x)

        if self.batch_size != 1:
            pred = torch.cat([i.reshape(1, 20) for i in pred], dim=0)
        return pred


class Android_MCNN(nn.Module):
    def __init__(self, BasicBlock, layers, num_class, batch_size, n_section):  # layers = [2, 2, 2, 2]
        super(Android_MCNN, self).__init__()
        self.norm_layer = nn.BatchNorm2d
        # self.inplanes = 48
        self.dilation = 1
        self.relu = nn.ReLU(inplace=True)

        channel = 64
        self.layer1 = self._make_layer(BasicBlock, 1, channel, layers[0], batch_size=batch_size, n_section=n_section)
        self.layer2 = self._make_layer(BasicBlock, channel, channel * 2, layers[1], batch_size=batch_size,
                                       n_section=n_section)
        self.layer3 = self._make_layer(BasicBlock, channel * 2, channel * 4, layers[2], batch_size=batch_size,
                                       n_section=n_section)
        self.layer4 = self._make_layer(BasicBlock, channel * 4, channel * 8, layers[3], batch_size=batch_size,
                                       n_section=n_section)
        # self.layer5 = self._make_layer(BasicBlock, 368, 368, layers[4])

        self.avgpool = torch.nn.AdaptiveAvgPool1d((1), )
        self.drop = nn.Dropout(0.5)

        self.fc = nn.Linear(channel * 8 * n_section,
                            channel * 4 * n_section)  # (channel * section * adaptive maxpooling output)
        self.fc2 = nn.Linear(channel * 4 * n_section, num_class)
        self.batch_size = batch_size
        self.n_section = n_section

    def _make_layer(self, block, inplanes, outplanes, blocks, batch_size, n_section):
        norm_layer = self.norm_layer

        layers = []
        for _ in range(1, blocks):
            layers.append(
                block(inplanes, inplanes, stride=1, norm_layer=norm_layer, batch_size=batch_size, n_section=12))
        layers.append(block(inplanes, outplanes, stride=1, norm_layer=norm_layer, batch_size=batch_size, n_section=12))
        return nn.Sequential(*layers)

    def forward(self, x):
        # See note [TorchScript super()]
        preds = []
        if self.batch_size != 1:
            for b in range(self.batch_size):
                c_x = self.layer1(x[b])
                c_x = self.layer2(c_x)
                c_x = self.layer3(c_x)
                c_x = self.layer4(c_x)
                # x = self.layer5(x)

                for i in range(self.n_section):
                    c_x[i] = self.avgpool(c_x[i])

                c_x = torch.cat([c_x[i] for i in range(self.n_section)], dim=2)
                c_x = torch.flatten(c_x)
                c_x = self.fc(c_x)
                c_x = self.drop(c_x)
                c_x = self.fc2(c_x)
                preds.append(c_x)

            if self.batch_size != 1:
                preds = torch.cat([i.reshape(1, 20) for i in preds], dim=0)
            return preds
        else:
            c_x = self.layer1(x)
            c_x = self.layer2(c_x)
            c_x = self.layer3(c_x)
            c_x = self.layer4(c_x)
            # x = self.layer5(x)

            for i in range(self.n_section):
                c_x[0][i] = self.avgpool(c_x[0][i])

            c_x = torch.cat([c_x[0][i] for i in range(self.n_section)], dim=2)
            c_x = torch.flatten(c_x)
            c_x = self.drop(c_x)
            c_x = self.fc(c_x)
            c_x = self.drop(c_x)
            c_x = self.fc2(c_x)
            preds.append(c_x)

            if self.batch_size != 1:
                preds = torch.cat([i.reshape(1, 20) for i in preds], dim=0)
            return preds


class load_MCNN4(nn.Module):  # 일자로 붙인 버전에서 GAP해결
    def __init__(self, channel, kernel_size=3, stride=1, padding=1, n_class=20, n_section=12, batch_size=None):
        super().__init__()

        self.relu = nn.ReLU()
        self.sm = nn.Softmax()
        self.n_section = 12
        self.batch_size = batch_size
        self.maxpool1d = torch.nn.MaxPool1d(kernel_size=2)
        self.drop = nn.Dropout(0.5)
        self.aap = nn.AdaptiveAvgPool1d((1), )
        self.amp = nn.AdaptiveAvgPool1d((4), )  # adaptive max pooling
        self.sigmoid = nn.Sigmoid()

        self.conv1d = nn.ModuleList()
        for i in range(n_class):
            self.conv1d.append(nn.Conv1d(1, channel, kernel_size=kernel_size, stride=stride, padding=padding))

        self.conv2d = nn.ModuleList()
        for i in range(n_class):
            self.conv2d.append(nn.Conv1d(channel, channel * 2, kernel_size=kernel_size, stride=stride, padding=padding))

        self.conv3d = nn.ModuleList()
        for i in range(n_class):
            self.conv3d.append(
                nn.Conv1d(channel * 2, channel * 4, kernel_size=kernel_size, stride=stride, padding=padding))

        self.conv4d = nn.ModuleList()
        for i in range(n_class):
            self.conv4d.append(
                nn.Conv1d(channel * 4, channel * 8, kernel_size=kernel_size, stride=stride, padding=padding))

        self.fc = nn.Linear(channel * 8 * n_section * 4,
                            channel * 8)  # (channel * section * adaptive maxpooling output)
        # self.fc = nn.Linear(channel * 8 * n_section, channel * 8)  # (channel * section * adaptive maxpooling output)
        self.fc2 = nn.Linear(channel * 8, n_class)

    def forward(self, x):
        pred = []
        for b in range(self.batch_size):
            for i in range(self.n_section):
                x[b][i] = self.conv1d[i](x[b][i])
                x[b][i] = self.relu(x[b][i])
                x[b][i] = self.maxpool1d(x[b][i])

            for i in range(self.n_section):
                x[b][i] = self.conv2d[i](x[b][i])
                x[b][i] = self.relu(x[b][i])
                x[b][i] = self.maxpool1d(x[b][i])

            for i in range(self.n_section):
                x[b][i] = self.conv3d[i](x[b][i])
                x[b][i] = self.relu(x[b][i])
                x[b][i] = self.maxpool1d(x[b][i])

            for i in range(self.n_section):
                x[b][i] = self.conv4d[i](x[b][i])
                x[b][i] = self.relu(x[b][i])
                x[b][i] = self.maxpool1d(x[b][i])
                # adaptive max pooling
                x[b][i] = self.amp(x[b][i])
                # x[b][i] = self.aap(x[b][i])

            c_x = torch.cat([x[b][i] for i in range(self.n_section)], dim=1)
            _c_x = torch.flatten(c_x)

        return _c_x


class Embedded_MFCN(nn.Module):  # 졸업 논문용
    def __init__(self, batch_size, num_class=20, n_section=6, kernel_size=5):  # layers = [2, 2, 2, 2]
        super(Embedded_MFCN, self).__init__()
        self.norm_layer = nn.BatchNorm2d
        self.dilation = 1
        self.relu = nn.ReLU(inplace=True)

        # self.Embedding_resolution = 256
        # self.Embedding_channels = 64
        self.d_model = 128
        self.n_head = 4
        self.num_layer = 3
        self.drop = nn.Dropout(0.5)
        # self.amp = nn.AdaptiveMaxPool1d((100), )
        self.amp = nn.AdaptiveMaxPool1d((1), )
        self.aap = nn.AdaptiveAvgPool1d((1), )
        self.kernel_size = kernel_size
        # down sampling for fixed Embedding Layer
        self.Embedded_layer = nn.ModuleList()  # [n stages, n_sections]
        for k in range(n_section):  # convolution filters for n_sections
            self.Embedded_layer.append(
                nn.Sequential(
                    EmbeddedBlock(1, 8, groups=1, kernel_size=self.kernel_size, MaxPool=True, pool_stride=2),
                    EmbeddedBlock(8, 32, groups=1, kernel_size=self.kernel_size, MaxPool=True, pool_stride=2),
                    EmbeddedBlock(32, 128, groups=1, kernel_size=self.kernel_size, MaxPool=True, pool_stride=2),
                    EmbeddedBlock(128, 512, groups=1, kernel_size=self.kernel_size, MaxPool=True, pool_stride=2),
                    EmbeddedBlock(512, 512, groups=1, kernel_size=self.kernel_size, MaxPool=False, Resnet=True),
                    EmbeddedBlock(512, 512, groups=1, kernel_size=self.kernel_size, MaxPool=False, Resnet=True),
                )
            )

        # encoder_layer = nn.TransformerEncoderLayer(d_model=self.d_model, nhead=self.n_head)
        # self.Transformer_s = nn.TransformerEncoder(encoder_layer, num_layers=self.num_layer)
        # self.pos_encoder = PositionalEncoding(128)
        self.fc = nn.Linear(512 * 6, 512)  # (channel * section * adaptive maxpooling output)
        self.fc2 = nn.Linear(512, num_class)
        self.batch_size = batch_size
        self.n_section = n_section

    def forward(self, x):
        # See note [TorchScript super()]
        preds = []

        c_x = [[[] for i in range(self.n_section)] for j in range(self.batch_size)]

        for b in range(self.batch_size):  # allign
            for s in range(self.n_section):
                c_x[b][s] = x[b][s]

        for b in range(self.batch_size):
            for s in range(self.n_section):
                c_x[b][s] = self.Embedded_layer[s](c_x[b][s])

        for b in range(self.batch_size):
            for s in range(self.n_section):
                c_x[b][s] = self.amp(c_x[b][s])

        for b in range(self.batch_size):
            c_x[b] = torch.cat([c_x[b][i] for i in range(self.n_section)], dim=1)

        # for b in range(self.batch_size):
        #     c_x[b] = torch.cat([c_x[b][i] for i in range(self.n_section)], dim=2)
        #     c_x[b] = self.amp(c_x[b])

        c_x = torch.cat(c_x, axis=0)
        c_x = torch.flatten(c_x, start_dim=1)

        c_x = self.fc(c_x)
        c_x = self.drop(c_x)
        c_x = self.fc2(c_x)
        preds.append(c_x)

        if self.batch_size != 1:
            preds = torch.cat([i.reshape(1, 20) for i in preds[0]], dim=0)
        return preds


class SELayer(nn.Module):
    def __init__(self, channel, reduction=4):
        super(SELayer, self).__init__()
        self.max_pool = nn.AdaptiveMaxPool1d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _, = x.size()
        y = self.max_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1)
        return x * y.expand_as(x)


class BasicBlock(nn.Module):
    def __init__(self, inplanes, outplanes, stride=1, base_width=64, norm_layer=None, batch_size=None, n_section=None,
                 groups=1, dilation=1, downsampling=None, ):
        super(BasicBlock, self).__init__()
        if norm_layer is None:
            norm_layer = nn.LayerNorm
        if groups != 1 or base_width != 64:
            raise ValueError('BasicBlock only supports groups=1 and base_width=64')
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1

        self.conv1 = conv1d(inplanes, outplanes, stride=stride)
        self.ln1 = norm_layer(outplanes)
        self.relu = nn.ReLU()
        self.stride = stride
        self.batch_size = batch_size
        self.n_section = n_section
        self.maxpool1d = torch.nn.MaxPool1d(kernel_size=2)

    def forward(self, x):
        identity = x

        if self.batch_size != 1:
            for b in range(self.batch_size):
                for i in range(self.n_section):
                    x[b][i] = self.conv1(x[b][i])
                    x[b][i] = self.ln1(x[b][i].unsqueeze(-1))
                    x[b][i] = x[b][i].squeeze(-1)
                    x[b][i] = self.maxpool1d(x[b][i])

                for i in range(self.n_section):
                    x[b][i] = torch.add(x[b][i], identity[b][i])
                    x[b][i] = self.relu(x[b][i])
            return x
        else:
            for i in range(self.n_section):
                x[0][i] = self.conv1(x[0][i])
                x[0][i] = self.ln1(x[0][i].unsqueeze(-1))
                x[0][i] = x[0][i].squeeze(-1)
                x[0][i] = self.maxpool1d(x[0][i])

            for i in range(self.n_section):
                x[0][i] = torch.add(x[0][i], identity[0][i])
                x[0][i] = self.relu(x[0][i])

            return x


def conv1d(inplain, outplain, stride=1, groups=1, dilation=1):
    return nn.Conv1d(inplain, outplain, kernel_size=3, stride=stride, padding=dilation, groups=groups, bias=False,
                     dilation=dilation)


class PositionalEncoding(nn.Module):

    def __init__(self, d_model, dropout=0.1, max_len=5000):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(p=dropout)

        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)

    def forward(self, x):
        x = x + self.pe[:x.size(0), :]
        return self.dropout(x)


class Embedded_MFCN2(nn.Module):  # 졸업 논문용
    def __init__(self, batch_size, num_class=20, n_section=6, kernel_size=5):  # layers = [2, 2, 2, 2]
        super(Embedded_MFCN2, self).__init__()
        self.norm_layer = nn.BatchNorm2d
        self.dilation = 1
        self.relu = nn.ReLU(inplace=True)

        # self.Embedding_resolution = 256
        # self.Embedding_channels = 64
        self.d_model = 128
        self.n_head = 4
        self.num_layer = 3
        self.drop = nn.Dropout(0.5)
        # self.amp = nn.AdaptiveMaxPool1d((100), )
        self.amp = nn.AdaptiveMaxPool1d((1), )
        self.aap = nn.AdaptiveAvgPool1d((1), )

        # down sampling for fixed Embedding Layer
        self.Embedded_layer = nn.ModuleList()  # [n stages, n_sections]
        for k in range(n_section):  # convolution filters for n_sections
            self.Embedded_layer.append(
                nn.Sequential(
                    EmbeddedBlock(1, 4, kernel_size=kernel_size, MaxPool=True, pool_stride=2),
                    EmbeddedBlock(4, 16, kernel_size=kernel_size, MaxPool=True, pool_stride=2),
                    EmbeddedBlock(16, 64, kernel_size=kernel_size, MaxPool=True, pool_stride=2),
                    EmbeddedBlock(64, 256, kernel_size=kernel_size, MaxPool=True, pool_stride=2),
                    EmbeddedBlock(256, 256, kernel_size=kernel_size, MaxPool=False),
                    EmbeddedBlock(256, 256, kernel_size=kernel_size, MaxPool=False)
                )
            )

        # encoder_layer = nn.TransformerEncoderLayer(d_model=self.d_model, nhead=self.n_head)
        # self.Transformer_s = nn.TransformerEncoder(encoder_layer, num_layers=self.num_layer)
        # self.pos_encoder = PositionalEncoding(128)
        self.fc = nn.Linear(256, 256)  # (channel * section * adaptive maxpooling output)
        self.fc2 = nn.Linear(256, num_class)
        self.batch_size = batch_size
        self.n_section = n_section

    def forward(self, x):
        # See note [TorchScript super()]
        preds = []

        c_x = [[[] for i in range(self.n_section)] for j in range(self.batch_size)]

        for b in range(self.batch_size):  # allign
            for s in range(self.n_section):
                c_x[b][s] = x[b][s]

        for b in range(self.batch_size):
            for s in range(self.n_section):
                c_x[b][s] = self.Embedded_layer[s](c_x[b][s])

        # for b in range(self.batch_size):
        #     for s in range(self.n_section):
        #         c_x[b][s] = self.amp(c_x[b][s])
        #
        # # for b in range(self.batch_size):#Transformer
        # #     for s in range(self.n_section):
        # #         c_x[b][s] = self.pos_encoder(c_x[b][s])
        # #         c_x[b][s] = self.Transformer_s(c_x[b][s])
        # #         c_x[b][s] = c_x[b][s].permute(1, 2, 0)
        # #         c_x[b][s] = self.aap(c_x[b][s])

        # for b in range(self.batch_size):#Transformer
        #     c_x[b] = torch.cat([c_x[b][i] for i in range(self.n_section)], dim=2)

        # for b in range(self.batch_size):
        #     c_x[b] = self.aap(c_x[b])
        #     c_x[b] = torch.cat([c_x[b][i] for i in range(self.n_section)], dim=2)

        # for b in range(self.batch_size):
        #     for s in range(self.n_section):
        #         c_x[b][s] = self.amp(c_x[b][s])
        #
        # for b in range(self.batch_size):#Transformer
        #     c_x[b] = torch.cat([c_x[b][i] for i in range(self.n_section)], dim=2)
        for b in range(self.batch_size):
            c_x[b] = torch.cat([c_x[b][i] for i in range(self.n_section)], dim=2)
            c_x[b] = self.amp(c_x[b])

        c_x = torch.cat(c_x, axis=0)
        c_x = torch.flatten(c_x, start_dim=1)

        c_x = self.fc(c_x)
        c_x = self.drop(c_x)
        c_x = self.fc2(c_x)
        preds.append(c_x)

        if self.batch_size != 1:
            preds = torch.cat([i.reshape(1, 20) for i in preds[0]], dim=0)
        return preds
#
#
# class EmbeddedBlock(nn.Module):
#     def __init__(self, down_in_channel, down_out_channel, kernel_size, groups=1, MaxPool=True, pool_stride=2):
#         super(EmbeddedBlock, self).__init__()
#         self.MaxPool = MaxPool
#         self.Resnet = Resnet
#
#         if self.MaxPool == True:
#             self.Embedded_layer = nn.Sequential(
#                 nn.Conv1d(down_in_channel, down_out_channel, groups=groups, kernel_size=kernel_size, stride=2),
#                 SELayer(down_out_channel),
#                 nn.MaxPool1d(kernel_size=4, stride=pool_stride),
#                 nn.ReLU()
#             )
#         else:
#             self.Embedded_layer = nn.Sequential(
#                 nn.Conv1d(down_in_channel, down_out_channel, kernel_size=kernel_size, groups=groups, stride=1,
#                           padding=2, padding_mode='zeros'),
#                 SELayer(down_out_channel),
#                 nn.ReLU()
#             )
#         # else:
#         #     self.Embedded_layer = nn.Sequential(
#         #             nn.Conv1d(down_in_channel, down_out_channel, kernel_size=kernel_size, groups = groups, stride=1),
#         #             SELayer(down_out_channel),
#         #             nn.ReLU()
#         #         )
#
#     def forward(self, x):
#         out = self.Embedded_layer(x)
#         return out


class EmbeddedBlock(nn.Module):
    def __init__(self, down_in_channel, down_out_channel,  kernel_size, groups=1, MaxPool=True, Resnet=False, pool_stride=2):
        super(EmbeddedBlock, self).__init__()
        self.MaxPool = MaxPool
        self.Resnet=Resnet

        if self.MaxPool == True:
            self.Embedded_layer = nn.Sequential(
                    nn.Conv1d(down_in_channel, down_out_channel, groups = groups, kernel_size=kernel_size, stride=2),
                    SELayer(down_out_channel),
                    nn.MaxPool1d(kernel_size=4, stride=pool_stride),
                    nn.ReLU()
                )
        else:
            self.Embedded_layer = nn.Sequential(
                    nn.Conv1d(down_in_channel, down_out_channel, kernel_size=kernel_size, groups = groups, stride=1,
                              padding = 2, padding_mode='zeros'),
                    SELayer(down_out_channel),
                    nn.ReLU()
                )
        # else:
        #     self.Embedded_layer = nn.Sequential(
        #             nn.Conv1d(down_in_channel, down_out_channel, kernel_size=kernel_size, groups = groups, stride=1),
        #             SELayer(down_out_channel),
        #             nn.ReLU()
        #         )

    def forward(self, x):
        if self.Resnet == True:
                residual = x
                x = self.Embedded_layer(x)
                out = x + residual
        else :
            out = self.Embedded_layer(x)
        return out

class Embedded_MFCN3(nn.Module):  # pretrained network + transformer
    def __init__(self, model_path, batch_size, n_section):
        super(Embedded_MFCN3, self).__init__()
        self.model = torch.load(model_path)

        self.relu = nn.ReLU(inplace=True)
        # self.Embedding_resolution = 256
        # self.Embedding_channels = 64
        self.d_model = 64
        self.n_head = 2
        self.num_layer = 2
        self.drop = nn.Dropout(0.5)
        # self.amp = nn.AdaptiveMaxPool1d((100), )
        self.aap1 = nn.AdaptiveAvgPool1d((64), )
        self.aap2 = nn.AdaptiveAvgPool1d((1), )
        # down sampling for fixed Embedding Layer

        encoder_layer = nn.TransformerEncoderLayer(d_model=self.d_model, nhead=self.n_head)
        self.Transformer_s = nn.TransformerEncoder(encoder_layer, num_layers=self.num_layer)
        self.pos_encoder = PositionalEncoding(self.d_model)
        self.fc = nn.Linear(512 * 6, 512)  # (channel * section * adaptive maxpooling output)
        self.fc2 = nn.Linear(512, 20)
        self.batch_size = batch_size
        self.n_section = n_section

    def forward(self, x):

        c_x = [[[] for i in range(self.n_section)] for j in range(self.batch_size)]
        preds = []

        for b in range(self.batch_size): #allign
            for s in range(self.n_section):
                c_x[b][s] =  self.model.Embedded_layer[s](x[b][s])

        for b in range(self.batch_size):
            for s in range(self.n_section):
                c_x[b][s] = self.aap1(c_x[b][s]) #2, 6, 512, x -> 2, 6, 512, 128

        for b in range(self.batch_size):#Transformer
            for s in range(self.n_section):
                c_x[b][s] = self.pos_encoder(c_x[b][s])
                c_x[b][s] = self.Transformer_s(c_x[b][s])
                #c_x[b][s] = c_x[b][s].permute(1, 2, 0)
                c_x[b][s] = self.aap2(c_x[b][s])   #2, 6, 512, 128 -> 2, 6, 512, 1

        for b in range(self.batch_size):
            c_x[b] = torch.cat([c_x[b][i] for i in range(self.n_section)], dim=1) #1, 3072, 1

        c_x = torch.cat(c_x, axis=0) #2, 3072, 1
        c_x = torch.flatten(c_x, start_dim=1)

        c_x = self.fc(c_x)
        c_x = self.drop(c_x)
        c_x = self.fc2(c_x)
        preds.append(c_x)

        if self.batch_size != 1:
            preds = torch.cat([i.reshape(1, 20) for i in preds[0]], dim=0)
        return preds

class Embedded_MFCN4(nn.Module):  # Embedded_2 + transformer
    def __init__(self, batch_size, n_section):
        super(Embedded_MFCN4, self).__init__()
        self.norm_layer = nn.BatchNorm2d
        self.dilation = 1
        self.relu = nn.ReLU(inplace=True)

        # self.Embedding_resolution = 256
        # self.Embedding_channels = 64
        self.d_model = 128
        self.n_head = 4
        self.num_layer = 3
        self.drop = nn.Dropout(0.5)
        # self.amp = nn.AdaptiveMaxPool1d((100), )
        self.amp = nn.AdaptiveMaxPool1d((1), )
        self.aap = nn.AdaptiveAvgPool1d((1), )

        # down sampling for fixed Embedding Layer
        self.Embedded_layer = nn.ModuleList()  # [n stages, n_sections]
        for k in range(n_section):  # convolution filters for n_sections
            self.Embedded_layer.append(
                nn.Sequential(
                    MEmbeddedBlock(1, 4, kernel_size=5, MaxPool=True, pool_stride=2),
                    MEmbeddedBlock(4, 16, kernel_size=5, MaxPool=True, pool_stride=2),
                    MEmbeddedBlock(16, 64, kernel_size=5, MaxPool=True, pool_stride=2),
                    MEmbeddedBlock(64, 256, kernel_size=5, MaxPool=True, pool_stride=2),
                    MEmbeddedBlock(256, 256, kernel_size=5, MaxPool=False),
                    MEmbeddedBlock(256, 256, kernel_size=5, MaxPool=False)
                )
            )

        self.w1 = nn.Parameter(torch.ones(6, dtype=torch.float32), requires_grad=True)
        self.w1_relu = nn.ReLU()
        self.epsilon = 1e+4

        self.fc = nn.Linear(256*6, 256)  # (channel * section * adaptive maxpooling output)
        self.fc2 = nn.Linear(256, 20)
        self.batch_size = batch_size
        self.n_section = n_section

    def forward(self, x):

        c_x = [[[] for i in range(self.n_section)] for j in range(self.batch_size)]
        preds = []

        for b in range(self.batch_size): #allign
            for s in range(self.n_section):
                c_x[b][s] =  self.Embedded_layer[s](x[b][s])

        for b in range(self.batch_size):
            for s in range(self.n_section):
                c_x[b][s] = self.amp(c_x[b][s]) #2, 6, 256, x -> 2, 6, 256, 1

        w1 = self.w1_relu(self.w1)
        weight = w1 / (torch.sum(w1, dim=0) + self.epsilon)
        # Connections for P6_0 and P7_0 to P6_1 respectively
        for b in range(self.batch_size):
            for s in range(self.n_section):
             c_x[b][s] = c_x[b][s] * weight[s]

        for b in range(self.batch_size):
            c_x[b] = torch.cat([c_x[b][i] for i in range(self.n_section)], dim=1) #1, 3072, 1

        c_x = torch.cat(c_x, axis=0) #2, 3072, 1
        c_x = torch.flatten(c_x, start_dim=1)

        c_x = self.fc(c_x)
        c_x = self.drop(c_x)
        c_x = self.fc2(c_x)
        preds.append(c_x)

        if self.batch_size != 1:
            preds = torch.cat([i.reshape(1, 20) for i in preds[0]], dim=0)
        return preds

class MEmbeddedBlock(nn.Module):
    def __init__(self, down_in_channel, down_out_channel,  kernel_size, groups=1, MaxPool=True, Resnet=False, pool_stride=2):
        super(MEmbeddedBlock, self).__init__()
        self.MaxPool = MaxPool
        self.Resnet=Resnet

        if self.MaxPool == True:
            self.Embedded_layer = nn.Sequential(
                    nn.Conv1d(down_in_channel, down_out_channel, groups = groups, kernel_size=5, stride=2,
                                padding_mode = 'zeros'),
                    SELayer(down_out_channel),
                    nn.MaxPool1d(kernel_size=2, stride=pool_stride),
                    nn.ReLU()
                )
        else:
            self.Embedded_layer = nn.Sequential(
                    nn.Conv1d(down_in_channel, down_out_channel, groups = groups, kernel_size=5, stride=1,
                                padding = 2,padding_mode = 'zeros'),
                    SELayer(down_out_channel),
                    nn.ReLU()
                )

    def forward(self, x):
        if self.Resnet == True:
            residual = x
            x = self.Embedded_layer(x)
            out = residual + x
        else :
            x = self.Embedded_layer(x)
            out = x
        return out